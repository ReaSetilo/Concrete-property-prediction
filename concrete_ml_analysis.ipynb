{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concrete Mixture Machine Learning Analysis\n",
    "## Prediction of Cost, Slump, Compressive Strength, and CO2 Emissions\n",
    "### Analysis across 7 different ash types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SETUP AND IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q openpyxl scikit-learn xgboost lightgbm catboost matplotlib seaborn pandas numpy joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "excel_file = 'REVISED_DATASET.xlsx'\n",
    "\n",
    "# Read all sheets (first 7 are ash types)\n",
    "xl = pd.ExcelFile(excel_file)\n",
    "ash_types = xl.sheet_names[:7]  # First 7 sheets are ash types\n",
    "\n",
    "print(\"Ash Types Found:\")\n",
    "for i, ash in enumerate(ash_types, 1):\n",
    "    print(f\"{i}. {ash}\")\n",
    "\n",
    "# Load all datasets\n",
    "datasets_raw = {}\n",
    "for ash_type in ash_types:\n",
    "    datasets_raw[ash_type] = pd.read_excel(excel_file, sheet_name=ash_type)\n",
    "    print(f\"\\n{ash_type}: {datasets_raw[ash_type].shape[0]} rows, {datasets_raw[ash_type].shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DATA EXPLORATION (BEFORE CLEANING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show histogram of entries before cleaning\n",
    "entries_before = {ash: len(datasets_raw[ash]) for ash in ash_types}\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(entries_before)), list(entries_before.values()), color='steelblue', alpha=0.7)\n",
    "plt.xlabel('Ash Type', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Number of Entries', fontsize=12, fontweight='bold')\n",
    "plt.title('Number of Entries per Ash Type (Before Cleaning)', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(len(entries_before)), [ash.replace(' 1', '') for ash in entries_before.keys()], rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEntries before cleaning:\")\n",
    "for ash, count in entries_before.items():\n",
    "    print(f\"{ash}: {count} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info for each ash type\n",
    "for ash_type in ash_types:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ASH TYPE: {ash_type}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nShape: {datasets_raw[ash_type].shape}\")\n",
    "    print(f\"\\nColumn Names:\")\n",
    "    print(datasets_raw[ash_type].columns.tolist())\n",
    "    print(f\"\\nMissing Values:\")\n",
    "    print(datasets_raw[ash_type].isnull().sum())\n",
    "    print(f\"\\nData Types:\")\n",
    "    print(datasets_raw[ash_type].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DATA CLEANING AND PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df, ash_type_name):\n",
    "    \"\"\"\n",
    "    Clean and prepare dataset for analysis\n",
    "    \"\"\"\n",
    "    print(f\"\\nCleaning {ash_type_name}...\")\n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    \n",
    "    # Create a copy\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Handle CO2 column - convert to numeric\n",
    "    if 'CO2_kgCO₂e / kg' in df_clean.columns:\n",
    "        df_clean['CO2_kgCO₂e / kg'] = pd.to_numeric(df_clean['CO2_kgCO₂e / kg'], errors='coerce')\n",
    "    \n",
    "    # Define target variables\n",
    "    target_vars = ['cost_USD_per_m3', 'Slump(mm)', 'compressive_strength_MPa_', 'CO2_kgCO₂e / kg']\n",
    "    \n",
    "    # Define input variables\n",
    "    input_vars = ['replacement_pct', 'cement_kg_m3', 'ash_kg_m3', 'fine_aggregate_kg_m3', \n",
    "                  'coarse_aggregate_kg_m3', 'pozzolan added(Fly Ash) kgm3', \n",
    "                  'superplasticizer_kg_m3', 'water kg_m3', 'curing_days']\n",
    "    \n",
    "    # Keep only necessary columns\n",
    "    necessary_cols = input_vars + target_vars + ['paper', 'reference']\n",
    "    df_clean = df_clean[[col for col in necessary_cols if col in df_clean.columns]]\n",
    "    \n",
    "    # Remove rows where ALL target variables are missing\n",
    "    target_cols_present = [col for col in target_vars if col in df_clean.columns]\n",
    "    df_clean = df_clean.dropna(subset=target_cols_present, how='all')\n",
    "    \n",
    "    # Fill missing values in input variables with median\n",
    "    for col in input_vars:\n",
    "        if col in df_clean.columns:\n",
    "            if df_clean[col].isnull().any():\n",
    "                median_val = df_clean[col].median()\n",
    "                df_clean[col].fillna(median_val, inplace=True)\n",
    "                print(f\"  Filled {col} missing values with median: {median_val:.2f}\")\n",
    "    \n",
    "    # Remove duplicates\n",
    "    before_dup = len(df_clean)\n",
    "    df_clean = df_clean.drop_duplicates(subset=input_vars + target_cols_present)\n",
    "    after_dup = len(df_clean)\n",
    "    if before_dup != after_dup:\n",
    "        print(f\"  Removed {before_dup - after_dup} duplicate rows\")\n",
    "    \n",
    "    # Remove outliers using IQR method for each variable\n",
    "    before_outliers = len(df_clean)\n",
    "    for col in input_vars + target_cols_present:\n",
    "        if col in df_clean.columns:\n",
    "            Q1 = df_clean[col].quantile(0.25)\n",
    "            Q3 = df_clean[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 3 * IQR  # Using 3*IQR for more lenient outlier removal\n",
    "            upper_bound = Q3 + 3 * IQR\n",
    "            df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "    \n",
    "    after_outliers = len(df_clean)\n",
    "    if before_outliers != after_outliers:\n",
    "        print(f\"  Removed {before_outliers - after_outliers} outlier rows\")\n",
    "    \n",
    "    print(f\"Final shape: {df_clean.shape}\")\n",
    "    print(f\"Rows removed: {df.shape[0] - df_clean.shape[0]} ({100*(df.shape[0] - df_clean.shape[0])/df.shape[0]:.1f}%)\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Clean all datasets\n",
    "datasets_clean = {}\n",
    "for ash_type in ash_types:\n",
    "    datasets_clean[ash_type] = clean_dataset(datasets_raw[ash_type], ash_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show histogram of entries after cleaning\n",
    "entries_after = {ash: len(datasets_clean[ash]) for ash in ash_types}\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Before cleaning\n",
    "ax1.bar(range(len(entries_before)), list(entries_before.values()), color='steelblue', alpha=0.7)\n",
    "ax1.set_xlabel('Ash Type', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Number of Entries', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Before Cleaning', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(range(len(entries_before)))\n",
    "ax1.set_xticklabels([ash.replace(' 1', '') for ash in entries_before.keys()], rotation=45, ha='right')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# After cleaning\n",
    "ax2.bar(range(len(entries_after)), list(entries_after.values()), color='coral', alpha=0.7)\n",
    "ax2.set_xlabel('Ash Type', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Number of Entries', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('After Cleaning', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(range(len(entries_after)))\n",
    "ax2.set_xticklabels([ash.replace(' 1', '') for ash in entries_after.keys()], rotation=45, ha='right')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nComparison of entries:\")\n",
    "print(f\"{'Ash Type':<15} {'Before':<10} {'After':<10} {'Removed':<10} {'% Removed'}\")\n",
    "print(\"-\" * 60)\n",
    "for ash in ash_types:\n",
    "    before = entries_before[ash]\n",
    "    after = entries_after[ash]\n",
    "    removed = before - after\n",
    "    pct = 100 * removed / before if before > 0 else 0\n",
    "    print(f\"{ash.replace(' 1', ''):<15} {before:<10} {after:<10} {removed:<10} {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. EXPLORATORY DATA ANALYSIS (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Outlier Visualization for Each Variable by Ash Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "target_vars = ['cost_USD_per_m3', 'Slump(mm)', 'compressive_strength_MPa_', 'CO2_kgCO₂e / kg']\n",
    "input_vars = ['replacement_pct', 'cement_kg_m3', 'ash_kg_m3', 'fine_aggregate_kg_m3', \n",
    "              'coarse_aggregate_kg_m3', 'pozzolan added(Fly Ash) kgm3', \n",
    "              'superplasticizer_kg_m3', 'water kg_m3', 'curing_days']\n",
    "\n",
    "all_vars = target_vars + input_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers for TARGET VARIABLES by ash type\n",
    "print(\"Creating outlier visualizations for TARGET VARIABLES...\\n\")\n",
    "\n",
    "for target_var in target_vars:\n",
    "    print(f\"\\nProcessing: {target_var}\")\n",
    "    \n",
    "    for ash_type in ash_types:\n",
    "        df = datasets_clean[ash_type]\n",
    "        \n",
    "        if target_var in df.columns and not df[target_var].isnull().all():\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "            \n",
    "            # Box plot\n",
    "            axes[0].boxplot(df[target_var].dropna(), vert=True)\n",
    "            axes[0].set_ylabel(target_var, fontsize=11, fontweight='bold')\n",
    "            axes[0].set_title(f'Box Plot', fontsize=12, fontweight='bold')\n",
    "            axes[0].grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # Histogram with KDE\n",
    "            axes[1].hist(df[target_var].dropna(), bins=30, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "            axes[1].set_xlabel(target_var, fontsize=11, fontweight='bold')\n",
    "            axes[1].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "            axes[1].set_title(f'Distribution', fontsize=12, fontweight='bold')\n",
    "            axes[1].grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # Add secondary axis for KDE\n",
    "            ax2 = axes[1].twinx()\n",
    "            df[target_var].dropna().plot(kind='kde', ax=ax2, color='red', linewidth=2)\n",
    "            ax2.set_ylabel('Density', fontsize=11, fontweight='bold')\n",
    "            ax2.grid(False)\n",
    "            \n",
    "            fig.suptitle(f'{target_var} - {ash_type}', fontsize=14, fontweight='bold', y=1.02)\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers for INPUT VARIABLES by ash type\n",
    "print(\"Creating outlier visualizations for INPUT VARIABLES...\\n\")\n",
    "\n",
    "for input_var in input_vars:\n",
    "    print(f\"\\nProcessing: {input_var}\")\n",
    "    \n",
    "    for ash_type in ash_types:\n",
    "        df = datasets_clean[ash_type]\n",
    "        \n",
    "        if input_var in df.columns and not df[input_var].isnull().all():\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "            \n",
    "            # Box plot\n",
    "            axes[0].boxplot(df[input_var].dropna(), vert=True)\n",
    "            axes[0].set_ylabel(input_var, fontsize=11, fontweight='bold')\n",
    "            axes[0].set_title(f'Box Plot', fontsize=12, fontweight='bold')\n",
    "            axes[0].grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # Histogram with KDE\n",
    "            axes[1].hist(df[input_var].dropna(), bins=30, alpha=0.7, color='coral', edgecolor='black')\n",
    "            axes[1].set_xlabel(input_var, fontsize=11, fontweight='bold')\n",
    "            axes[1].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "            axes[1].set_title(f'Distribution', fontsize=12, fontweight='bold')\n",
    "            axes[1].grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # Add secondary axis for KDE\n",
    "            ax2 = axes[1].twinx()\n",
    "            df[input_var].dropna().plot(kind='kde', ax=ax2, color='darkred', linewidth=2)\n",
    "            ax2.set_ylabel('Density', fontsize=11, fontweight='bold')\n",
    "            ax2.grid(False)\n",
    "            \n",
    "            fig.suptitle(f'{input_var} - {ash_type}', fontsize=14, fontweight='bold', y=1.02)\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Pearson Correlation Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Pearson correlation matrix for each ash type\n",
    "print(\"Creating correlation matrices for each ash type...\\n\")\n",
    "\n",
    "for ash_type in ash_types:\n",
    "    df = datasets_clean[ash_type]\n",
    "    \n",
    "    # Select only numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = df[numeric_cols].corr(method='pearson')\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    \n",
    "    # Create heatmap\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8},\n",
    "                vmin=-1, vmax=1)\n",
    "    \n",
    "    plt.title(f'Pearson Correlation Matrix - {ash_type}', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Correlation matrix created for {ash_type}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Frequency Distributions by Ash Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frequency distributions for each variable by ash type\n",
    "print(\"Creating frequency distribution plots...\\n\")\n",
    "\n",
    "# For each variable, create separate plots for each ash type\n",
    "for var in all_vars:\n",
    "    print(f\"\\nProcessing variable: {var}\")\n",
    "    \n",
    "    for ash_type in ash_types:\n",
    "        df = datasets_clean[ash_type]\n",
    "        \n",
    "        if var in df.columns and not df[var].isnull().all():\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            # Create histogram\n",
    "            n, bins, patches = plt.hist(df[var].dropna(), bins=25, alpha=0.7, \n",
    "                                        color='mediumseagreen', edgecolor='black', linewidth=1.2)\n",
    "            \n",
    "            # Add KDE overlay\n",
    "            ax2 = plt.gca().twinx()\n",
    "            df[var].dropna().plot(kind='kde', ax=ax2, color='darkblue', linewidth=2.5)\n",
    "            ax2.set_ylabel('Density', fontsize=12, fontweight='bold')\n",
    "            ax2.grid(False)\n",
    "            \n",
    "            plt.gca().set_xlabel(var, fontsize=12, fontweight='bold')\n",
    "            plt.gca().set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "            plt.gca().set_title(f'Frequency Distribution of {var}\\n{ash_type}', \n",
    "                               fontsize=14, fontweight='bold', pad=15)\n",
    "            plt.gca().grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # Add statistics box\n",
    "            stats_text = f\"Mean: {df[var].mean():.2f}\\nMedian: {df[var].median():.2f}\\nStd: {df[var].std():.2f}\"\n",
    "            plt.gca().text(0.02, 0.98, stats_text, transform=plt.gca().transAxes,\n",
    "                          fontsize=10, verticalalignment='top',\n",
    "                          bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MODEL TRAINING PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 10 machine learning models\n",
    "def get_models():\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Ridge Regression': Ridge(),\n",
    "        'Lasso Regression': Lasso(),\n",
    "        'ElasticNet': ElasticNet(),\n",
    "        'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "        'Random Forest': RandomForestRegressor(random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "        'XGBoost': XGBRegressor(random_state=42, verbosity=0),\n",
    "        'LightGBM': LGBMRegressor(random_state=42, verbose=-1),\n",
    "        'CatBoost': CatBoostRegressor(random_state=42, verbose=0)\n",
    "    }\n",
    "    return models\n",
    "\n",
    "# Define hyperparameter grids for tuning\n",
    "def get_param_grids():\n",
    "    param_grids = {\n",
    "        'Linear Regression': {},\n",
    "        'Ridge Regression': {'alpha': [0.1, 1.0, 10.0]},\n",
    "        'Lasso Regression': {'alpha': [0.1, 1.0, 10.0]},\n",
    "        'ElasticNet': {'alpha': [0.1, 1.0], 'l1_ratio': [0.3, 0.5, 0.7]},\n",
    "        'Decision Tree': {'max_depth': [5, 10, 15], 'min_samples_split': [2, 5]},\n",
    "        'Random Forest': {'n_estimators': [50, 100], 'max_depth': [10, 20], 'min_samples_split': [2, 5]},\n",
    "        'Gradient Boosting': {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]},\n",
    "        'XGBoost': {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]},\n",
    "        'LightGBM': {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'num_leaves': [31, 50]},\n",
    "        'CatBoost': {'iterations': [50, 100], 'learning_rate': [0.01, 0.1], 'depth': [4, 6]}\n",
    "    }\n",
    "    return param_grids\n",
    "\n",
    "print(\"Model definitions ready!\")\n",
    "print(f\"\\nModels to be trained: {len(get_models())}\")\n",
    "for i, model_name in enumerate(get_models().keys(), 1):\n",
    "    print(f\"{i}. {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split data into train (75%), test (15%), and validation (10%)\n",
    "def split_data(X, y, random_state=42):\n",
    "    # First split: 75% train, 25% temp\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.25, random_state=random_state)\n",
    "    \n",
    "    # Second split: 15% test (60% of temp), 10% validation (40% of temp)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.4, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val\n",
    "\n",
    "print(\"Data splitting function ready!\")\n",
    "print(\"Split ratios: Train=75%, Test=15%, Validation=10%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. MODEL TRAINING AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize storage for results\n",
    "all_results = {}\n",
    "best_models = {}\n",
    "\n",
    "# Create directory for saving models\n",
    "os.makedirs('trained_models', exist_ok=True)\n",
    "\n",
    "print(\"Starting model training across all ash types and target variables...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models for each ash type and target variable\n",
    "for ash_type in ash_types:\n",
    "    print(f\"\\n\\n{'#'*80}\")\n",
    "    print(f\"# PROCESSING ASH TYPE: {ash_type}\")\n",
    "    print(f\"{'#'*80}\\n\")\n",
    "    \n",
    "    df = datasets_clean[ash_type]\n",
    "    \n",
    "    # Initialize results storage for this ash type\n",
    "    all_results[ash_type] = {}\n",
    "    best_models[ash_type] = {}\n",
    "    \n",
    "    # Prepare input features\n",
    "    X_cols = [col for col in input_vars if col in df.columns]\n",
    "    \n",
    "    for target_var in target_vars:\n",
    "        if target_var not in df.columns or df[target_var].isnull().all():\n",
    "            print(f\"  ⚠ Skipping {target_var} - not available in {ash_type}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"TARGET VARIABLE: {target_var}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Prepare data\n",
    "        df_target = df.dropna(subset=[target_var])\n",
    "        X = df_target[X_cols]\n",
    "        y = df_target[target_var]\n",
    "        \n",
    "        if len(X) < 10:\n",
    "            print(f\"  ⚠ Insufficient data ({len(X)} samples) for {target_var}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nDataset size: {len(X)} samples\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, X_val, y_train, y_test, y_val = split_data(X, y)\n",
    "        \n",
    "        print(f\"Train: {len(X_train)} | Test: {len(X_test)} | Validation: {len(X_val)}\")\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        \n",
    "        # Train models\n",
    "        models = get_models()\n",
    "        param_grids = get_param_grids()\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            print(f\"\\n  Training {model_name}...\")\n",
    "            \n",
    "            try:\n",
    "                # Hyperparameter tuning\n",
    "                if param_grids[model_name]:\n",
    "                    grid_search = GridSearchCV(model, param_grids[model_name], \n",
    "                                              cv=min(3, len(X_train)//10 if len(X_train) >= 30 else 2),\n",
    "                                              scoring='r2', n_jobs=-1)\n",
    "                    grid_search.fit(X_train_scaled, y_train)\n",
    "                    best_model = grid_search.best_estimator_\n",
    "                    print(f\"    Best params: {grid_search.best_params_}\")\n",
    "                else:\n",
    "                    best_model = model\n",
    "                    best_model.fit(X_train_scaled, y_train)\n",
    "                \n",
    "                # Predictions\n",
    "                y_train_pred = best_model.predict(X_train_scaled)\n",
    "                y_test_pred = best_model.predict(X_test_scaled)\n",
    "                y_val_pred = best_model.predict(X_val_scaled)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                results[model_name] = {\n",
    "                    'model': best_model,\n",
    "                    'scaler': scaler,\n",
    "                    'train_r2': r2_score(y_train, y_train_pred),\n",
    "                    'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "                    'train_mae': mean_absolute_error(y_train, y_train_pred),\n",
    "                    'test_r2': r2_score(y_test, y_test_pred),\n",
    "                    'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "                    'test_mae': mean_absolute_error(y_test, y_test_pred),\n",
    "                    'val_r2': r2_score(y_val, y_val_pred),\n",
    "                    'val_rmse': np.sqrt(mean_squared_error(y_val, y_val_pred)),\n",
    "                    'val_mae': mean_absolute_error(y_val, y_val_pred)\n",
    "                }\n",
    "                \n",
    "                print(f\"    Train R²: {results[model_name]['train_r2']:.4f} | Test R²: {results[model_name]['test_r2']:.4f} | Val R²: {results[model_name]['val_r2']:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    ✗ Error: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Store results\n",
    "        all_results[ash_type][target_var] = results\n",
    "        \n",
    "        # Find best model based on validation R²\n",
    "        if results:\n",
    "            best_model_name = max(results.keys(), key=lambda x: results[x]['val_r2'])\n",
    "            best_models[ash_type][target_var] = {\n",
    "                'name': best_model_name,\n",
    "                'model': results[best_model_name]['model'],\n",
    "                'scaler': results[best_model_name]['scaler'],\n",
    "                'metrics': results[best_model_name],\n",
    "                'features': X_cols\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n  ★ BEST MODEL: {best_model_name}\")\n",
    "            print(f\"    Validation R²: {results[best_model_name]['val_r2']:.4f}\")\n",
    "            print(f\"    Validation RMSE: {results[best_model_name]['val_rmse']:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            model_path = f\"trained_models/{ash_type.replace(' ', '_')}_{target_var.replace(' ', '_').replace('/', '_')}_best.pkl\"\n",
    "            joblib.dump({\n",
    "                'model': results[best_model_name]['model'],\n",
    "                'scaler': results[best_model_name]['scaler'],\n",
    "                'features': X_cols,\n",
    "                'ash_type': ash_type,\n",
    "                'target_var': target_var,\n",
    "                'model_name': best_model_name\n",
    "            }, model_path)\n",
    "            print(f\"    Model saved: {model_path}\")\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"MODEL TRAINING COMPLETED!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. MODEL COMPARISON AND VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison tables for each ash type and target variable\n",
    "print(\"Creating model comparison tables...\\n\")\n",
    "\n",
    "for ash_type in ash_types:\n",
    "    if ash_type not in all_results or not all_results[ash_type]:\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"ASH TYPE: {ash_type}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    for target_var in target_vars:\n",
    "        if target_var not in all_results[ash_type] or not all_results[ash_type][target_var]:\n",
    "            continue\n",
    "        \n",
    "        results = all_results[ash_type][target_var]\n",
    "        \n",
    "        print(f\"\\nTarget: {target_var}\")\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"{'Model':<25} {'Train R²':<12} {'Test R²':<12} {'Val R²':<12} {'Val RMSE':<12} {'Val MAE':<12}\")\n",
    "        print(\"-\" * 100)\n",
    "        \n",
    "        # Sort by validation R²\n",
    "        sorted_results = sorted(results.items(), key=lambda x: x[1]['val_r2'], reverse=True)\n",
    "        \n",
    "        for model_name, metrics in sorted_results:\n",
    "            print(f\"{model_name:<25} {metrics['train_r2']:<12.4f} {metrics['test_r2']:<12.4f} \"\n",
    "                  f\"{metrics['val_r2']:<12.4f} {metrics['val_rmse']:<12.4f} {metrics['val_mae']:<12.4f}\")\n",
    "        \n",
    "        print(\"-\" * 100)\n",
    "        print(f\"★ Best: {sorted_results[0][0]} (Val R²: {sorted_results[0][1]['val_r2']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance comparison\n",
    "print(\"\\nCreating performance comparison visualizations...\\n\")\n",
    "\n",
    "for ash_type in ash_types:\n",
    "    if ash_type not in all_results or not all_results[ash_type]:\n",
    "        continue\n",
    "    \n",
    "    for target_var in target_vars:\n",
    "        if target_var not in all_results[ash_type] or not all_results[ash_type][target_var]:\n",
    "            continue\n",
    "        \n",
    "        results = all_results[ash_type][target_var]\n",
    "        \n",
    "        # Create comparison plot\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        model_names = list(results.keys())\n",
    "        train_r2 = [results[m]['train_r2'] for m in model_names]\n",
    "        test_r2 = [results[m]['test_r2'] for m in model_names]\n",
    "        val_r2 = [results[m]['val_r2'] for m in model_names]\n",
    "        \n",
    "        x = np.arange(len(model_names))\n",
    "        width = 0.25\n",
    "        \n",
    "        # R² comparison\n",
    "        axes[0].bar(x - width, train_r2, width, label='Train', alpha=0.8, color='steelblue')\n",
    "        axes[0].bar(x, test_r2, width, label='Test', alpha=0.8, color='coral')\n",
    "        axes[0].bar(x + width, val_r2, width, label='Validation', alpha=0.8, color='mediumseagreen')\n",
    "        axes[0].set_xlabel('Model', fontsize=11, fontweight='bold')\n",
    "        axes[0].set_ylabel('R² Score', fontsize=11, fontweight='bold')\n",
    "        axes[0].set_title('R² Score Comparison', fontsize=12, fontweight='bold')\n",
    "        axes[0].set_xticks(x)\n",
    "        axes[0].set_xticklabels(model_names, rotation=45, ha='right', fontsize=9)\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # RMSE comparison\n",
    "        val_rmse = [results[m]['val_rmse'] for m in model_names]\n",
    "        axes[1].bar(model_names, val_rmse, alpha=0.8, color='indianred')\n",
    "        axes[1].set_xlabel('Model', fontsize=11, fontweight='bold')\n",
    "        axes[1].set_ylabel('RMSE', fontsize=11, fontweight='bold')\n",
    "        axes[1].set_title('Validation RMSE', fontsize=12, fontweight='bold')\n",
    "        axes[1].tick_params(axis='x', rotation=45, labelsize=9)\n",
    "        plt.setp(axes[1].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "        axes[1].grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # MAE comparison\n",
    "        val_mae = [results[m]['val_mae'] for m in model_names]\n",
    "        axes[2].bar(model_names, val_mae, alpha=0.8, color='mediumpurple')\n",
    "        axes[2].set_xlabel('Model', fontsize=11, fontweight='bold')\n",
    "        axes[2].set_ylabel('MAE', fontsize=11, fontweight='bold')\n",
    "        axes[2].set_title('Validation MAE', fontsize=12, fontweight='bold')\n",
    "        axes[2].tick_params(axis='x', rotation=45, labelsize=9)\n",
    "        plt.setp(axes[2].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "        axes[2].grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        fig.suptitle(f'Model Performance Comparison\\n{ash_type} - {target_var}', \n",
    "                    fontsize=14, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. FEATURE IMPORTANCE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance for best models\n",
    "print(\"Creating feature importance visualizations for best models...\\n\")\n",
    "\n",
    "for ash_type in ash_types:\n",
    "    if ash_type not in best_models or not best_models[ash_type]:\n",
    "        continue\n",
    "    \n",
    "    for target_var in target_vars:\n",
    "        if target_var not in best_models[ash_type]:\n",
    "            continue\n",
    "        \n",
    "        best_model_info = best_models[ash_type][target_var]\n",
    "        model = best_model_info['model']\n",
    "        model_name = best_model_info['name']\n",
    "        features = best_model_info['features']\n",
    "        \n",
    "        # Extract feature importance\n",
    "        feature_importance = None\n",
    "        \n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            # Tree-based models\n",
    "            feature_importance = model.feature_importances_\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            # Linear models\n",
    "            feature_importance = np.abs(model.coef_)\n",
    "        \n",
    "        if feature_importance is not None:\n",
    "            # Create DataFrame for visualization\n",
    "            importance_df = pd.DataFrame({\n",
    "                'Feature': features,\n",
    "                'Importance': feature_importance\n",
    "            }).sort_values('Importance', ascending=False)\n",
    "            \n",
    "            # Normalize to sum to 1 (weights)\n",
    "            importance_df['Weight'] = importance_df['Importance'] / importance_df['Importance'].sum()\n",
    "            \n",
    "            # Create visualization\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "            \n",
    "            # Bar plot\n",
    "            colors = plt.cm.viridis(np.linspace(0, 1, len(importance_df)))\n",
    "            ax1.barh(importance_df['Feature'], importance_df['Weight'], color=colors, alpha=0.8)\n",
    "            ax1.set_xlabel('Normalized Weight', fontsize=12, fontweight='bold')\n",
    "            ax1.set_ylabel('Feature', fontsize=12, fontweight='bold')\n",
    "            ax1.set_title('Feature Weights (Normalized)', fontsize=13, fontweight='bold')\n",
    "            ax1.grid(axis='x', alpha=0.3)\n",
    "            \n",
    "            # Pie chart\n",
    "            ax2.pie(importance_df['Weight'], labels=importance_df['Feature'], autopct='%1.1f%%',\n",
    "                   startangle=90, colors=colors)\n",
    "            ax2.set_title('Feature Weight Distribution', fontsize=13, fontweight='bold')\n",
    "            \n",
    "            fig.suptitle(f'Feature Importance - Best Model ({model_name})\\n{ash_type} - {target_var}',\n",
    "                        fontsize=14, fontweight='bold', y=0.98)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"\\nFeature weights for {ash_type} - {target_var}:\")\n",
    "            print(importance_df[['Feature', 'Weight']].to_string(index=False))\n",
    "            print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. SUMMARY OF BEST MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table of best models\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"SUMMARY OF BEST MODELS PER ASH TYPE AND TARGET VARIABLE\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "for ash_type in ash_types:\n",
    "    if ash_type not in best_models or not best_models[ash_type]:\n",
    "        continue\n",
    "    \n",
    "    for target_var in target_vars:\n",
    "        if target_var not in best_models[ash_type]:\n",
    "            continue\n",
    "        \n",
    "        best_model_info = best_models[ash_type][target_var]\n",
    "        metrics = best_model_info['metrics']\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Ash Type': ash_type.replace(' 1', ''),\n",
    "            'Target Variable': target_var,\n",
    "            'Best Model': best_model_info['name'],\n",
    "            'Train R²': f\"{metrics['train_r2']:.4f}\",\n",
    "            'Test R²': f\"{metrics['test_r2']:.4f}\",\n",
    "            'Val R²': f\"{metrics['val_r2']:.4f}\",\n",
    "            'Val RMSE': f\"{metrics['val_rmse']:.4f}\",\n",
    "            'Val MAE': f\"{metrics['val_mae']:.4f}\"\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\", summary_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "\n",
    "# Save summary to CSV\n",
    "summary_df.to_csv('trained_models/best_models_summary.csv', index=False)\n",
    "print(\"\\nSummary saved to: trained_models/best_models_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. EXPORT MODELS FOR GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive model registry for the GUI\n",
    "model_registry = {\n",
    "    'ash_types': ash_types,\n",
    "    'target_variables': target_vars,\n",
    "    'input_variables': input_vars,\n",
    "    'models': best_models\n",
    "}\n",
    "\n",
    "# Save registry\n",
    "joblib.dump(model_registry, 'trained_models/model_registry.pkl')\n",
    "print(\"Model registry saved: trained_models/model_registry.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL MODELS EXPORTED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal models saved: {sum(len(best_models[ash]) for ash in best_models)}\")\n",
    "print(f\"Storage location: trained_models/\")\n",
    "print(\"\\nReady for GUI application!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. COMPLETION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"#\" + \" \"*78 + \"#\")\n",
    "print(\"#\" + \" \"*20 + \"ANALYSIS COMPLETED SUCCESSFULLY!\" + \" \"*25 + \"#\")\n",
    "print(\"#\" + \" \"*78 + \"#\")\n",
    "print(\"#\"*80)\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Download the 'trained_models' folder\")\n",
    "print(\"2. Run the GUI application (concrete_predictor_gui.py)\")\n",
    "print(\"3. Make predictions using the best models for each target variable\")\n",
    "print(\"\\n\" + \"#\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
